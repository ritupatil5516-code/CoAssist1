ğŸ¯ Overview

The Banking Copilot is an LLM-driven, context-engineered retrieval-augmented generation (RAG) app designed to answer banking/credit card questions using:
	â€¢	Customer data JSON files
(account-summary.json, statements.json, transactions.json, payments.json)
	â€¢	A rules PDF (agreement.pdf) describing official interest and fee rules

It is built on LlamaIndex, FAISS, BM25, and a Meta Llama-3.3-70B model, with Qwen3-8B embeddings.

The app supports questions such as:
	â€¢	â€œWhat is my interest this month?â€
	â€¢	â€œWhen was my last payment made?â€
	â€¢	â€œWhere did I spend the most this year?â€


âš™ï¸ Components

1. Data Layer
	â€¢	JSON Files:
	â€¢	account-summary.json â†’ account status, credit limit, current balance
	â€¢	statements.json â†’ ending balances, interest charged, due dates
	â€¢	transactions.json â†’ all transactions, with flags for interest and merchantName
	â€¢	payments.json â†’ payment history, last payment detection
	â€¢	Agreement PDF:
	â€¢	Defines rules for interest calculation and other credit card policies

â¸»

2. Ingestion Layer
	â€¢	Pydantic Models parse JSON into structured objects.
	â€¢	Nodes: Each record becomes a TextNode with metadata:
	â€¢	ym = Year-Month for grouping
	â€¢	dt_iso = timestamp for freshness scoring
	â€¢	raw = raw JSON payload

â¸»

3. Indexing
	â€¢	FAISS VectorStoreIndex
	â€¢	Stores dense embeddings (via Qwen3-8B embedding model)
	â€¢	Supports semantic search
	â€¢	BM25Retriever
	â€¢	Provides lexical keyword retrieval
	â€¢	Ensures robust handling of numeric or keyword-based queries

â¸»

4. Hybrid Retrieval + Freshness
	â€¢	Combines FAISS + BM25 scores:
	final_score = Î± * faiss_score + (1 - Î±) * bm25_score

	â€¢	Applies freshness decay:
	final_score = final_score * exp(-Î» * age_in_days)

	Ensures:
	â€¢	Semantic coverage
	â€¢	Keyword robustness
	â€¢	Recent documents favored (freshness)

â¸»

5. Reranking
	â€¢	Optional LLM-based reranker (LLMRerank)
	â€¢	Takes the top-N candidates and re-scores them using Llama-3.3-70B
	â€¢	Produces a reranked top-K context window

â¸»

6. Prompting Layer (Context Engineering)
	â€¢	System Prompt (prompts/system.md) defines banking rules:
	â€¢	Interest calculation preference order
	â€¢	Payment detection
	â€¢	Spend analysis logic
	â€¢	Always cite [n] snippets
	â€¢	Style Prompt (prompts/assistant_style.md) ensures:
	â€¢	Concise, well-structured answers
	â€¢	A â€œFields usedâ€ line for transparency

â¸»

7. Answer Generation
	â€¢	Final context is passed with rules + style into Llama-3.3-70B
	â€¢	LLM produces:
	â€¢	Direct answer
	â€¢	Reasoning steps (short)
	â€¢	Citations (referring to retrieved nodes)
	â€¢	Fields used summary

â¸»

ğŸ”„ Step-by-Step Flow
	1.	User asks a question (e.g., â€œWhat is my interest this month?â€)
	2.	Retriever fetches relevant nodes:
	â€¢	FAISS semantic match
	â€¢	BM25 keyword match
	â€¢	Hybrid scoring + freshness bias
	3.	LLM reranker (optional) re-scores the candidates
	4.	Top-K snippets are passed into the system+style prompts
	5.	Llama-3.3-70B generates the final response, citing relevant nodes
	6.	Streamlit chat UI displays the answer + expandable retrieved context

â¸»

ğŸ“Š Example Q&A Flow

Q: â€œWhat is my total interest this month?â€
	â€¢	Retrieval brings:
	â€¢	AGGREGATE ym=2024-08 interest_from_statements_total=45.12
	â€¢	STATEMENT { interestCharged=45.12 }
	â€¢	LLM applies rule 1 (prefer statement aggregate)
	â€¢	Answer:
Your interest for 2024-08 is 45.12 [1].
Fields used: STATEMENT.interestCharged

â¸»

âœ… Key Advantages
	â€¢	LLM-driven: all reasoning delegated to Llama-3.3-70B
	â€¢	Context-engineered: rules explicitly steer LLM
	â€¢	Hybrid + Freshness: balances recall, precision, and recency
	â€¢	Modular: FAISS, BM25, and rerankers can be swapped easily
	â€¢	Transparent: citations + fields used for auditability
